{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Tex Makros -->\n",
    "$$\n",
    "\\newcommand{\\Q}{\\mathbb{Q}}\n",
    "\\newcommand{\\R}{\\mathbb{R}}\n",
    "\\newcommand{\\C}{\\mathbb{C}}\n",
    "\\newcommand{\\N}{\\mathbb{N}}\n",
    "\\newcommand{\\Sn}{\\mathbb{S}^{n-1} }\n",
    "\\newcommand\\Z{\\mathbb Z}\n",
    "\\DeclareMathOperator{\\sgn}{\\mathrm{sgn}}\n",
    "$$\n",
    "<!-- End of Tex Makros -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assignment was handed in by:  \n",
    "**...Namehere...** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Exercise  | 1  | 2  | 3  | 4  | 5  |\n",
    "|:----------|:---|:---|:---|:---|:---|\n",
    "| Points    |    |    |    |    |    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  **Algorithmic Spectral Graph Theory - WS 2020/2021**\n",
    "_Alexander Taveira Blomenhofer, Markus Schweighofer_\n",
    "### General Rules: \n",
    "\n",
    "+ Write your name into the name field!\n",
    "+ You will find **exercises** across the notebook. There are two types of exercises:\n",
    "    - *Numbered exercises* are marked as `Exercise 1:`, `Exercise 2:` etc. These will grant points towards the module which are necessary to successfully finish the module. \n",
    "    - *Unenumerated exercises* are marked as `Exercise*:`  They exist to serve your own, personal understanding or to provide further context. They will not count towards module progression.\n",
    "+ Write your own comments and theoretical solutions into separate Markdown cells, preferably into one single cell directly after the exercise was stated. Do not mix your solutions into the problem statement cells that we wrote! \n",
    "+ Code cells are not affected by this rule. If we provide you with starter code, you can extend it in the same cell. \n",
    "+ You are completely **free to ignore all starter code** we wrote for you. Particularly, this is true if you want to program in a language other than Julia. \n",
    "+ When you solve an exercise in $n$ Markdown cells, start the cell with `Solution to Exercise i - Part (k/n):`, if $i$ is the number of the exercise and if it is the $k$-th part of the solution. Similarly, start with `Solution to Exercise - Part (k/n):`, if it is an unnumbered exercise. \n",
    "+ Whenever code cells belong to the solution of an exercise, indicate this by starting the cell with a comment containing `Solution to Exercise i:`, if $i$ is the number of the exercise, and with `Solution to Exercise:`, if it is an unnumbered exercise. \n",
    "+ Whenever you do not know how to program something, **read the [(Julia-)documentation!](https://docs.julialang.org/en/v1/stdlib/LinearAlgebra/)**  \n",
    "+ If you run this notebook locally on your computer, then you might need to install some additional [Julia-packages](https://docs.julialang.org/en/v1/stdlib/Pkg/). This can e.g. be done from the Julia console or conveniently from Jupyterlab by running commands such as: \n",
    "    ```\n",
    "    using Pkg;\n",
    "    Pkg.add(\"JuMP\");\n",
    "    ```\n",
    "    These commands need to be run only once and can be deleted afterwards! However, whenever you run a notebook using, say, _JuMP_ in your code after installation, you have to tell the kernel by writing `using JuMP;` somewhere before it is being used. \n",
    "+ Useful packages for this exercise sheet are: [JuMP](https://jump.dev/JuMP.jl/dev/installation/) and [COSMO](https://oxfordcontrol.github.io/COSMO.jl/stable/#Installation-1).\n",
    "+ If your Browser does not render the $\\LaTeX$ / **Markdown** properly, then please try using Firefox or Chromium.\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Exercise Sheet 1 - *Cutting the Social Graph*\n",
    "\n",
    "In the following you will find a table with the current participants of our lecture. We want to construct a \"social\" graph $G$ by writing zeros and ones into this table, encoding the following edge relation in between 2 participants:   \n",
    "There is an edge between distinct participants $a, b$ in the **symmetric** graph $G$ if **you** think that $a$ and $b$ **both** find each other sympathetic. \n",
    "(You do not have to know whether they actually find each other sympathetic: Your graph depends just on your personal guess).  \n",
    "\n",
    "| Participants | Benjamin | Daniel | David | Eduard | Esther | Jakob | J. Dix    | J. Riehle    | Joschka | Juliane | Lennart | Marcel | Tim |\n",
    "|:-------------|:---------|:-------|:------|:-------|:-------|:------|:----------|:-------------|:--------|:--------|:--------|:-------|:----|\n",
    "| Benjamin     | 0        |        |       |        |        |       |           |              |         |         |         |        |     |\n",
    "| Daniel       |          | 0      |       |        |        |       |           |              |         |         |         |        |     |\n",
    "| David        |          |        | 0     |        |        |       |           |              |         |         |         |        |     |\n",
    "| Eduard       |          |        |       | 0      |        |       |           |              |         |         |         |        |     |\n",
    "| Esther       |          |        |       |        | 0      |       |           |              |         |         |         |        |     |\n",
    "| Jakob        |          |        |       |        |        | 0     |           |              |         |         |         |        |     |\n",
    "| J. Dix       |          |        |       |        |        |       | 0         |              |         |         |         |        |     |\n",
    "| J. Riehle    |          |        |       |        |        |       |           | 0            |         |         |         |        |     |\n",
    "| Joschka      |          |        |       |        |        |       |           |              | 0       |         |         |        |     |\n",
    "| Juliane      |          |        |       |        |        |       |           |              |         | 0       |         |        |     |\n",
    "| Lennart      |          |        |       |        |        |       |           |              |         |         | 0       |        |     |\n",
    "| Marcel       |          |        |       |        |        |       |           |              |         |         |         | 0      |     |\n",
    "| Tim          |          |        |       |        |        |       |           |              |         |         |         |        | 0   |\n",
    "\n",
    "\n",
    "You do not want to be too harmonic or anti-harmonic: You should always assume that there exist some pairings which do not like each other and some which get along well.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct your table as an adjacency matrix $A := \\mathrm{Adj}(G)$ in Julia (or your favourite supported programming language). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# your code goes here....\n",
    "# n = 0;\n",
    "# A = 0;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cuts in Graphs\n",
    "\n",
    "Let $n\\in \\mathbb \\N_0$. A *cut* in the graph $G$ on $\\{1,\\ldots, n\\}$ is a partition of $\\{1,\\ldots, n\\}$ into two disjoint subsets $S$ and $T$.  \n",
    "\n",
    "Even though the definition talks only about vertices, the intuition behind it is that we want to *grab scissors* and cut every **edge** which connects a vertex from $S$ with a vertex from $T$.\n",
    "\n",
    "For $i,j\\in \\{1,\\ldots, n\\}$, we say that an edge $(i,j)$ is *cut* by the cut, when ($i\\in S$ and $j\\in T$) or when ($i\\in T$ and $j\\in S$). We want to find a cut $(S, T)$ such that the set of cut edges \n",
    "$$\n",
    "\\mathrm{Cut}_{S, T} := \\{(i,j) \\in S\\times T \\mid A_{ij} = 1 \\}\n",
    "$$\n",
    "has as many elements as possible. To this end, it is always possible to assume $T = \\{1,\\ldots, n\\}\\setminus S $ without loss of generality, i.e. that $T$ is the largest subset of $\\{1,\\ldots, n\\}$ disjoint with $S$ (why?).\n",
    "\n",
    "\n",
    "## Exercises \n",
    "\n",
    "`Exercise 1:`\n",
    "1. Explain in great detail and accuracy what the optimization problem\n",
    "    \\begin{align} \n",
    "    (MC) \\qquad \\mathrm{maximize}\\quad \\sum_{i, j = 1}^n \\frac{A_{ij}}{8} &(x_i-x_j)^2 \\\\\n",
    "    \\text{subject to}\\qquad\\qquad &x_1,\\ldots, x_n \\in \\{-1,1\\}\n",
    "    \\end{align}\n",
    "    has to do with the above problem. \n",
    "2. Show that the objective function in the problem above can be replaced  by    \n",
    "$$\n",
    "(MC2)\\qquad  c - \\sum_{i, j = 1}^n \\frac{A_{ij}}{4} x_ix_j     \n",
    "$$\n",
    "where $c\\in \\Q$ is some appropriately fixed constant, without changing the values it attains for $x = (x_1,\\ldots, x_n) \\in \\{-1,1\\}^n$. What is the value of $c$?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reminder:** Let $B\\in \\R^{n\\times n}$. Recall that the following are equivalent:\n",
    "   1. $B$ is *positive semidefinite* (psd), i.e. $B$ is symmetric and for all $v\\in \\R^n$,  $v^{T}Bv \\geq 0$.\n",
    "   2. $B$ is *Gramian*, i.e. there exists a matrix $V\\in \\R^{n\\times n}$ such that $B = V^{T}V$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Exercise 2:`\n",
    "Show that the problem\n",
    "    \\begin{align} \n",
    "    (SDP) \\qquad \\mathrm{maximize}\\quad c-\\sum_{i, j = 1}^n &\\frac{A_{ij}}{4} B_{ij} \\\\\n",
    "    \\text{subject to}\\qquad\\quad &B\\in \\R^{n\\times n} \\text{ symmetric and psd,}\\\\\n",
    "                                  &B_{11} = \\ldots = B_{nn} = 1 \n",
    "    \\end{align}\n",
    "    attains at least the value of $(MC)$.\n",
    "    To this end, use the _reminder_ to write $B_{ij} = v_i^{T}v_j $ for some vectors $v_1,\\ldots, v_n\\in \\R^n$. Then, argue why the optimization problem $(MC)$ is obtained back whenever the $v_i$ in this decomposition of $B$ are restricted to be multiples of the first unit vector $e_1 := (1,0,\\ldots, 0)\\in \\R^n$.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding large cuts\n",
    "\n",
    "The problem $(SDP)$ can be solved very fast by modern solvers (unlike $(MC)$, which is a computationally very hard problem for large $n$). In the following we will make use of such a solver, called [COSMO](https://oxfordcontrol.github.io/COSMO.jl/stable/#Installation-1) and the modeling language  [JuMP](https://jump.dev/JuMP.jl/dev/installation/). You are highly encouraged to read the documentation of JuMP in order to find out how to declare an optimization problem such as $(SDP)$ in Julia. \n",
    "\n",
    "To aid your start, we did already provide you with some code below that shows you how to declare constraints and call the solver. The objective functions below are to be understood as **examples**. They have nothing to do with the specific ones you should use in the problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Exercise 4:` \n",
    "1. Write a program that solves $(SDP)$, where $A$ is the adjacency matrix of the social graph you constructed in the beginning. Test your code with several other graphs.\n",
    "2. What value do you get for the graph you chose?\n",
    "3. What value do you get for the complete graph $K_n$ on $n$ vertices (where each two distinct vertices are connected)? Try several different values of $n$.\n",
    "4. Use your brain and combinatorics to deduce the size of a maximal cut for the complete graph $K_n$ in closed form for any $n\\in \\N_0$. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# some starter code \n",
    "using JuMP;  # modeling language that allows us to write down optimization problems such as (SDP)\n",
    "using COSMO; # solver for problems such as (SDP)\n",
    "\n",
    "n = 7;\n",
    "\n",
    "sdp = Model(COSMO.Optimizer);\n",
    "\n",
    "# declare new variables\n",
    "@variable(sdp, B[1:n, 1:n] in PSDCone()) # the matrix B is being restricted to be PSD.\n",
    "for i=1:n\n",
    "    fix(B[i,i],1); # defines constraints\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$ \\begin{alignat*}{1}\\max\\quad & B_{1,1} + B_{1,2} + B_{2,2} + B_{2,3} + B_{2,4} + B_{2,5} + B_{2,6} + B_{2,7} + 1\\\\\n",
       "\\text{Subject to} \\quad & [B_{1,1}, B_{1,2}, B_{2,2}, B_{1,3}, B_{2,3}, B_{3,3}, B_{1,4}, B_{2,4}, B_{3,4}, B_{4,4}, B_{1,5}, B_{2,5}, B_{3,5}, B_{4,5}, B_{5,5}, B_{1,6}, B_{2,6}, B_{3,6}, B_{4,6}, B_{5,6}, B_{6,6}, B_{1,7}, B_{2,7}, B_{3,7}, B_{4,7}, B_{5,7}, B_{6,7}, B_{7,7}] \\in MathOptInterface.PositiveSemidefiniteConeTriangle(7)\\\\\n",
       " & B_{1,1} = 1.0\\\\\n",
       " & B_{2,2} = 1.0\\\\\n",
       " & B_{3,3} = 1.0\\\\\n",
       " & B_{4,4} = 1.0\\\\\n",
       " & B_{5,5} = 1.0\\\\\n",
       " & B_{6,6} = 1.0\\\\\n",
       " & B_{7,7} = 1.0\\\\\n",
       "\\end{alignat*}\n",
       " $$"
      ],
      "text/plain": [
       "A JuMP Model\n",
       "Maximization problem with:\n",
       "Variables: 28\n",
       "Objective function type: GenericAffExpr{Float64,VariableRef}\n",
       "`Array{VariableRef,1}`-in-`MathOptInterface.PositiveSemidefiniteConeTriangle`: 1 constraint\n",
       "`VariableRef`-in-`MathOptInterface.EqualTo{Float64}`: 7 constraints\n",
       "Model mode: AUTOMATIC\n",
       "CachingOptimizer state: EMPTY_OPTIMIZER\n",
       "Solver name: COSMO\n",
       "Names registered in the model: B"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now set objective function\n",
    "\n",
    "# Part I - complete graph \n",
    "using LinearAlgebra; \n",
    "A = zeros(n,n);\n",
    "c = 0;\n",
    "\n",
    "@objective(sdp, Max, 1+B[1,1] + sum(B[i,2] for i=1:n)); \n",
    "sdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------\n",
      "          COSMO v0.7.5 - A Quadratic Objective Conic Solver\n",
      "                         Michael Garstka\n",
      "                University of Oxford, 2017 - 2020\n",
      "------------------------------------------------------------------\n",
      "\n",
      "Problem:  x ∈ R^{28},\n",
      "          constraints: A ∈ R^{35x28} (35 nnz),\n",
      "          matrix size to factor: 63x63,\n",
      "          Floating-point precision: Float64\n",
      "Sets:     DensePsdConeTriangle of dim: 28\n",
      "          ZeroSet of dim: 7\n",
      "Settings: ϵ_abs = 1.0e-04, ϵ_rel = 1.0e-04,\n",
      "          ϵ_prim_inf = 1.0e-06, ϵ_dual_inf = 1.0e-04,\n",
      "          ρ = 0.1, σ = 1e-06, α = 1.6,\n",
      "          max_iter = 2500,\n",
      "          scaling iter = 10 (on),\n",
      "          check termination every 40 iter,\n",
      "          check infeasibility every 40 iter,\n",
      "          KKT system solver: QDLDL\n",
      "Setup Time: 0.06ms\n",
      "\n",
      "Iter:\tObjective:\tPrimal Res:\tDual Res:\tRho:\n",
      "1\t-6.5118e+01\t1.1826e+01\t4.4242e-01\t1.0000e-01\n",
      "40\t-6.4485e+00\t2.2847e-01\t1.5515e-03\t1.0000e-01\n",
      "80\t-7.7862e+00\t3.0505e-02\t2.0246e-03\t1.2424e+00\n",
      "120\t-7.9686e+00\t4.4762e-03\t4.0606e-04\t1.2424e+00\n",
      "160\t-7.9954e+00\t6.5619e-04\t7.5616e-05\t1.2424e+00\n",
      "200\t-7.9993e+00\t9.6102e-05\t1.3452e-05\t1.2424e+00\n",
      "\n",
      "------------------------------------------------------------------\n",
      ">>> Results\n",
      "Status: \u001b[32mSolved\u001b[39m\n",
      "Iterations: 200\n",
      "Optimal objective: -7.999\n",
      "Runtime: 0.004s (3.88ms)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimize!(sdp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35.000592631154504"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objective_value(sdp,result=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Part II - social graph \n",
    "\n",
    "# nothing here yet ...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now employ a magical heuristic to **\"round\"** a solution of $(SDP)$ towards a solution of $(MC)$. \n",
    "\n",
    "The trick goes as follows: \n",
    "1. Let $B$ denote some solution of $(SDP)$. Compute a matrix $V$ such that $B = V^TV$. _You can use the cholesky_decomposition provided by ..._\n",
    "2. Draw a  random vector $x$ from a Gaussian distribution with mean vector $0$ and covariance matrix $I_n$. \n",
    "3. Set $y:= Vx\\in \\R^n$ and observe that the expected covariance matrix of $y$ is exactly $B$.  This means that if we average the function $(MC2)$ over many random choices of $x$, we will get the optimal value of $(SDP)$. However, **the entries of $y$ are generally not in \\{-1,1\\}^n!**\n",
    "4. Therefore, set $z:= z_{B,x} := (\\sgn(y_1), \\ldots, \\sgn(y_n)) \\in \\{-1, 1\\}^n$. (Here, we say that for $a\\in \\R$, $\\sgn(a)$ is $1$ if $a\\geq 0$ and $-1$ if $a<0$.\n",
    "\n",
    "This will certainly produce **some** solution $z$, but a priori, we do not know if it produces a solution that **attains a high value** for $(MC2)$ if $B$ was optimal. We thus want to test this solution experimentally: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Exercise 5:` \n",
    "1. Write a function that takes some solution $B$ of $(SDP)$ as an argument and produces the vector $z_{B,x}$ as above.\n",
    "2. For the complete graph on 14 nodes, compute a solution of $(SDP)$ and run the function at least 100 times (with different random choices of $x$) to find some vector $z_{B,x}$ which attains the highest value for $(MC)$ over all your choices of $x$. \n",
    "3. Compare the best value you get to the theoretical solution from `Exercise 4.4`. What happens for even $n$ and the complete graph $K_n$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gw_round"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hints: \n",
    "# 1. It is recommendable to first write a function that draws one x and computes z_{B,x} \n",
    "\n",
    "\"Takes a psd matrix B with diagonal entries == 1 and rounds it to a solution of MaxCut\"\n",
    "function gw_round(B)\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# compute 100 roundings of Gaussian samples \n",
    "\n",
    "# hints: \n",
    "# 1. value.(B) queries the value of B after the optimization was run\n",
    "# 2. If value.(B) is positive definite, a Gramian decomposition can be found e.g. by a cholesky decomposition\n",
    "# 3. If value.(B) is only psd (up to numerical errors) but not positive definite, there exists methods to obtain \"generalized Cholesky decompositions\", which need not to be unique. \n",
    "#    A cheap trick that you can use in that case is to compute cholesky(value.(B + 0.001*I)).U instead in order to make the matrix positive definite.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# comparison: \n",
    "\n",
    "# theoretically optimal value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# comparison: \n",
    "# best computed rounding\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Exercise*:` \n",
    "Imagine you are a teacher that wants to assign their lecture's participants into two exercise classes $S$ and $T$ for a group project. Find arguments why the teacher should choose a **Maximal Cut** _(i.e. a cut that cuts the largest number of edges possible)_ in the social graph from above to assign the groups $S$ and $T$. Find also arguments against it. Which side wins? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further context\n",
    "\n",
    "It can be shown that the rounding procedure described here will always achieve an approximation ration of $\\alpha \\approx 0.86...$. In precise terms, writing\n",
    "$$\n",
    "\\ell(x) := c-\\sum_{i, j = 1}^n \\frac{A_{ij}}{4} x_ix_j\n",
    "$$\n",
    "this means that the random variable $z$ constructed from the optimal solution $B$ of $(SDP)$ will satisfy   \n",
    "$$\n",
    "\\mathbb E_{x}[\\ell(z_{B,x})] \\geq \\alpha \\: (c-\\sum_{i, j = 1}^n \\frac{A_{ij}}{4} B_{ij})\n",
    "$$\n",
    "\n",
    "More information including two formal proofs of the above can be found here:  \n",
    "[Lecture notes of Jin-Yi Cai](http://pages.cs.wisc.edu/~jyc/02-810notes/lecture20.pdf)  \n",
    "[Lecture notes of Matt DeVos](http://www.sfu.ca/~mdevos/notes/semidef/GW.pdf)  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.1",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
